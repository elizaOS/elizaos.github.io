name: Run Pipelines

on:
  schedule:
    # Run at 23:00 UTC daily
    - cron: "0 23 * * *"
  workflow_dispatch: # Allow manual trigger
    inputs:
      force_ingest:
        description: "Force reingest of data"
        type: boolean
        default: false
        required: false
      force_process:
        description: "Force reprocessing/re-export of data"
        type: boolean
        default: false
        required: false
      force_summaries:
        description: "Force regeneration of summaries"
        type: boolean
        default: false
        required: false
      summary_types_to_run:
        description: "Comma-separated list of summary types to run (repository,overall,contributors)"
        type: string
        default: "repository,overall,contributors"
      summary_intervals_to_run:
        description: "Comma-separated list of intervals to run (daily,weekly,monthly)"
        type: string
        default: "daily,weekly,monthly"
      startDate:
        description: "Start date for data processing (format: YYYY-MM-DD)"
        type: string
        required: false
      endDate:
        description: "End date for data processing (format: YYYY-MM-DD)"
        type: string
        required: false

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
  PIPELINE_DATA_BRANCH: "_data" # Define branch name as environment variable
  DATA_DIR: "data"

  # =============================================================================
  # FORK-SPECIFIC CONFIG - Edit these values for your fork
  # =============================================================================
  PIPELINE_START_DATE: "2024-10-15"
  PIPELINE_PROJECT_CONTEXT: |
    We are ElizaOS. Our mission is to develop an extensible, modular, open-source
    AI agent framework that thrives across both Web2 and Web3 ecosystems.

    Core Philosophy:
    - Autonomy & Adaptability: Agents should learn, reason, and adapt across diverse tasks.
    - Modularity & Composability: AI architectures should be modular for iterative improvements.
    - Decentralization & Open Collaboration: Moving beyond centralized control towards distributed intelligence.
  PIPELINE_REPOS: |
    [
      {"owner": "elizaos", "name": "eliza", "defaultBranch": "main"},
      {"owner": "elizaos", "name": "elizaos.github.io", "defaultBranch": "main"},
      {"owner": "elizaos", "name": "docs", "defaultBranch": "main"},
      {"owner": "elizaos", "name": "x402.elizaos.ai", "defaultBranch": "main"},
      {"owner": "elizaos", "name": "spartan", "defaultBranch": "main"},
      {"owner": "elizaos", "name": "jeju", "defaultBranch": "main"},
      {"owner": "elizaos-plugins", "name": "plugin-solana", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-knowledge", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-chart", "defaultBranch": "main"},
      {"owner": "elizaos-plugins", "name": "plugin-analytics", "defaultBranch": "main"},
      {"owner": "elizaos-plugins", "name": "plugin-jupiter", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-trust", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-rolodex", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-birdeye", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-digitaltwin", "defaultBranch": "main"},
      {"owner": "elizaos-plugins", "name": "plugin-mysql", "defaultBranch": "main"},
      {"owner": "elizaos-plugins", "name": "plugin-elizaos-cloud", "defaultBranch": "main"},
      {"owner": "elizaos-plugins", "name": "registry", "defaultBranch": "main"},
      {"owner": "elizaos-plugins", "name": "plugin-twitter", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-auton8n", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-evm", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-coingecko", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-farcaster", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-mcp", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-autocoder", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-discord", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-telegram", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-openrouter", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-openai", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-anthropic", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-relay", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-email", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-ollama", "defaultBranch": "1.x"},
      {"owner": "elizaos-plugins", "name": "plugin-pdf", "defaultBranch": "1.x"}
    ]
  PIPELINE_BOT_USERS: |
    ["dependabot", "dependabot-preview", "renovate", "renovate-bot", "renovate[bot]",
     "github-actions", "github-actions[bot]", "github-bot", "codecov", "codecov-io",
     "stale[bot]", "semantic-release-bot", "copilot-pull-request-reviewer", "imgbot",
     "coderabbitai", "codefactor-io", "graphite-app", "google-labs-jules[bot]", "cursor", "claude"]
  PIPELINE_SCORING: |
    {
      "pullRequest": {"base": 4, "merged": 16, "perReview": 1.5, "perApproval": 2, "perComment": 0.2, "descriptionMultiplier": 0.003, "complexityMultiplier": 0.5, "optimalSizeBonus": 5, "maxPerDay": 10, "closingIssueBonus": 5},
      "reaction": {"diminishingReturns": 0.7, "base": 0.5, "received": 0.1, "maxPerDay": 10, "types": {"thumbs_up": 1.2, "thumbs_down": 0.5, "laugh": 1.0, "hooray": 1.5, "confused": 0.5, "heart": 1.5, "rocket": 1.5, "eyes": 1.2}},
      "issue": {"base": 2, "perComment": 0.1, "withLabelsMultiplier": {"bug": 1.8, "enhancement": 1.4, "documentation": 1.0}, "closedBonus": 2, "resolutionSpeedMultiplier": 1.0},
      "review": {"base": 4, "approved": 1, "changesRequested": 2, "commented": 0.5, "detailedFeedbackMultiplier": 0.002, "thoroughnessMultiplier": 1.3, "maxPerDay": 8},
      "comment": {"base": 0.2, "substantiveMultiplier": 0.001, "diminishingReturns": 0.7, "maxPerThread": 3},
      "codeChange": {"perLineAddition": 0.005, "perLineDeletion": 0.01, "perFile": 0.15, "maxLines": 800, "testCoverageBonus": 2.0}
    }
  PIPELINE_TAGS: |
    {
      "area": [
        {"name": "core", "category": "AREA", "patterns": ["core/", "src/core", "packages/core"], "weight": 2.5, "description": "Core system components and libraries"},
        {"name": "ui", "category": "AREA", "patterns": ["components/", "ui/", "src/components", "pages/"], "weight": 1.8, "description": "User interface and component libraries"},
        {"name": "docs", "category": "AREA", "patterns": ["docs/", "README", ".md"], "weight": 1.5, "description": "Documentation and guides"},
        {"name": "infra", "category": "AREA", "patterns": [".github/", "docker", "k8s", ".yml", ".yaml"], "weight": 1.8, "description": "Infrastructure and deployment"},
        {"name": "tests", "category": "AREA", "patterns": ["test/", "tests/", ".spec.", ".test."], "weight": 2.0, "description": "Test files and test infrastructure"}
      ],
      "role": [
        {"name": "architect", "category": "ROLE", "patterns": ["feat:", "refactor:", "breaking:"], "weight": 2.5, "description": "Architects major features and refactorings"},
        {"name": "maintainer", "category": "ROLE", "patterns": ["fix:", "chore:", "bump:", "update:"], "weight": 2.0, "description": "Maintains codebase health and fixes issues"},
        {"name": "feature-dev", "category": "ROLE", "patterns": ["feat:", "feature:", "add:"], "weight": 2.0, "description": "Develops new features"},
        {"name": "bug-fixer", "category": "ROLE", "patterns": ["fix:", "bug:", "hotfix:"], "weight": 2.2, "description": "Identifies and fixes bugs"},
        {"name": "docs-writer", "category": "ROLE", "patterns": ["docs:", "documentation:"], "weight": 1.2, "description": "Writes and improves documentation"},
        {"name": "reviewer", "category": "ROLE", "patterns": ["review:", "feedback:"], "weight": 1.8, "description": "Reviews code and provides feedback"},
        {"name": "devops", "category": "ROLE", "patterns": ["ci:", "cd:", "deploy:", "build:"], "weight": 2.2, "description": "Works on CI/CD and deployment infrastructure"}
      ],
      "tech": [
        {"name": "typescript", "category": "TECH", "patterns": [".ts", ".tsx", "tsconfig"], "weight": 1.5, "description": "TypeScript language expertise"},
        {"name": "react", "category": "TECH", "patterns": ["react", ".jsx", ".tsx", "component"], "weight": 1.4, "description": "React framework expertise"},
        {"name": "nextjs", "category": "TECH", "patterns": ["next.", "nextjs", "pages/", "app/"], "weight": 1.6, "description": "Next.js framework expertise"},
        {"name": "tailwind", "category": "TECH", "patterns": ["tailwind", "tw-", "className"], "weight": 1.2, "description": "Tailwind CSS expertise"},
        {"name": "database", "category": "TECH", "patterns": ["sql", "db", "database", "query", "schema"], "weight": 1.7, "description": "Database and SQL expertise"},
        {"name": "api", "category": "TECH", "patterns": ["api", "rest", "graphql", "endpoint"], "weight": 1.6, "description": "API design and implementation"}
      ]
    }
jobs:
  ingest-export:
    name: Ingest/Export Pipeline
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: write # Needed for pushing to branches

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      # Set common conditional variables
      - name: Set conditional variables
        id: set-vars
        run: |
          START_DATE_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.startDate != '' && format(' -a {0}', github.event.inputs.startDate) || '' }}"
          END_DATE_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.endDate != '' && format(' -b {0}', github.event.inputs.endDate) || '' }}"

          FORCE_INGEST_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.force_ingest == 'true' && ' -f' || '' }}"

          FORCE_PROCESS_ARG="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.force_process == 'true' && ' -f' || '' }}"

          echo "start_date_arg=$START_DATE_ARG" >> $GITHUB_ENV
          echo "end_date_arg=$END_DATE_ARG" >> $GITHUB_ENV
          echo "force_ingest_arg=$FORCE_INGEST_ARG" >> $GITHUB_ENV
          echo "force_process_arg=$FORCE_PROCESS_ARG" >> $GITHUB_ENV

      # Set up pipeline-data branch worktree
      - name: Setup pipeline-data branch
        uses: ./.github/actions/pipeline-data
        with:
          operation: setup
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}
          data_dir: ${{ env.DATA_DIR }}

      # Restore database from pipeline-data branch
      - name: Restore database
        uses: ./.github/actions/restore-db
        with:
          operation: restore
          dump_dir: ${{ env.DATA_DIR }}/dump
          db_path: ${{ env.DATA_DIR }}/db.sqlite

      - name: Run ingest pipeline
        run: bun run pipeline ingest${{ env.force_ingest_arg }}${{ env.start_date_arg }}${{ env.end_date_arg }}

      - name: Run process pipeline
        run: bun run pipeline process${{ env.force_process_arg }}

      - name: Run export pipeline # Export everything missing + overwrite last 2 days to ensure overlap
        run: |
          bun run pipeline export${{ env.start_date_arg }}${{ env.end_date_arg }}${{ env.force_process_arg }}
          bun run pipeline export --days 2 -f

      # Dump SQLite database to diffable files before updating pipeline-data branch
      - name: Dump SQLite database
        uses: ./.github/actions/restore-db
        with:
          operation: dump
          db_path: ${{ env.DATA_DIR }}/db.sqlite
          dump_dir: ${{ env.DATA_DIR }}/dump

      # Update pipeline-data branch with new data
      - name: Update pipeline-data branch
        uses: ./.github/actions/pipeline-data
        with:
          operation: update
          data_dir: ${{ env.DATA_DIR }}
          commit_message: "Ingest/export run: $(date -u +'%Y-%m-%d %H:%M')"
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}

      # Cleanup worktree (always runs)
      - name: Cleanup
        if: always()
        uses: ./.github/actions/pipeline-data
        with:
          operation: cleanup
          data_dir: ${{ env.DATA_DIR }}
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}

  generate-summaries:
    name: Generate Summaries
    needs: ingest-export
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: write # Needed for pushing to branches
    # Skip summary generation if all summary types are disabled in a manual run
    if: ${{ github.event_name != 'workflow_dispatch' || github.event.inputs.summary_types_to_run != '' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install --frozen-lockfile

      # Set up pipeline-data branch worktree
      - name: Setup pipeline-data branch
        uses: ./.github/actions/pipeline-data
        with:
          operation: setup
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}
          data_dir: ${{ env.DATA_DIR }}

      # Restore database from pipeline-data branch
      - name: Restore database
        uses: ./.github/actions/restore-db
        with:
          operation: restore
          dump_dir: ${{ env.DATA_DIR }}/dump
          db_path: ${{ env.DATA_DIR }}/db.sqlite

      # Determine which intervals and types to run
      - name: Set run conditions
        id: conditions
        run: |
          DAY_OF_WEEK=$(date +%u) # 1=Mon, 7=Sun

          # Scheduled runs
          if [ "${{ github.event_name }}" == "schedule" ]; then
            echo "RUN_DAILY=true" >> $GITHUB_OUTPUT
            if [ "$DAY_OF_WEEK" = "3" ] || [ "$DAY_OF_WEEK" = "6" ]; then
              echo "RUN_WEEKLY=true" >> $GITHUB_OUTPUT
            fi
            if [ "$DAY_OF_WEEK" = "7" ]; then
              echo "RUN_MONTHLY=true" >> $GITHUB_OUTPUT
              echo "RUN_CONTRIBUTORS=true" >> $GITHUB_OUTPUT
            fi
            echo "RUN_REPOSITORIES=true" >> $GITHUB_OUTPUT
            echo "RUN_OVERALL=true" >> $GITHUB_OUTPUT

          # Manual runs
          else
            SUMMARY_TYPES="${{ github.event.inputs.summary_types_to_run }}"
            SUMMARY_INTERVALS="${{ github.event.inputs.summary_intervals_to_run }}"

            if [[ "$SUMMARY_INTERVALS" == *'daily'* ]]; then echo "RUN_DAILY=true"; else echo "RUN_DAILY=false"; fi >> $GITHUB_OUTPUT
            if [[ "$SUMMARY_INTERVALS" == *'weekly'* ]]; then echo "RUN_WEEKLY=true"; else echo "RUN_WEEKLY=false"; fi >> $GITHUB_OUTPUT
            if [[ "$SUMMARY_INTERVALS" == *'monthly'* ]]; then echo "RUN_MONTHLY=true"; else echo "RUN_MONTHLY=false"; fi >> $GITHUB_OUTPUT
            if [[ "$SUMMARY_TYPES" == *'contributors'* ]]; then echo "RUN_CONTRIBUTORS=true"; else echo "RUN_CONTRIBUTORS=false"; fi >> $GITHUB_OUTPUT
            if [[ "$SUMMARY_TYPES" == *'repository'* ]]; then echo "RUN_REPOSITORIES=true"; else echo "RUN_REPOSITORIES=false"; fi >> $GITHUB_OUTPUT
            if [[ "$SUMMARY_TYPES" == *'overall'* ]]; then echo "RUN_OVERALL=true"; else echo "RUN_OVERALL=false"; fi >> $GITHUB_OUTPUT
          fi

      # Repository summaries must run BEFORE overall summaries
      # because overall summaries aggregate repository summaries
      - name: Run Repository Summaries
        if: steps.conditions.outputs.RUN_REPOSITORIES == 'true'
        uses: ./.github/actions/run-summary
        with:
          summary-type: "repository"
          daily: ${{ steps.conditions.outputs.RUN_DAILY }}
          weekly: ${{ steps.conditions.outputs.RUN_WEEKLY }}
          monthly: ${{ steps.conditions.outputs.RUN_MONTHLY }}
          force: ${{ github.event.inputs.force_summaries }}
          start-date: ${{ github.event.inputs.startDate }}
          end-date: ${{ github.event.inputs.endDate }}

      - name: Run Contributor Summaries
        if: steps.conditions.outputs.RUN_CONTRIBUTORS == 'true'
        uses: ./.github/actions/run-summary
        with:
          summary-type: "contributors"
          daily: ${{ steps.conditions.outputs.RUN_DAILY }}
          weekly: ${{ steps.conditions.outputs.RUN_WEEKLY }}
          monthly: ${{ steps.conditions.outputs.RUN_MONTHLY }}
          force: ${{ github.event.inputs.force_summaries }}
          start-date: ${{ github.event.inputs.startDate }}
          end-date: ${{ github.event.inputs.endDate }}

      - name: Run Overall Summaries
        if: steps.conditions.outputs.RUN_OVERALL == 'true'
        uses: ./.github/actions/run-summary
        with:
          summary-type: "overall"
          daily: ${{ steps.conditions.outputs.RUN_DAILY }}
          weekly: ${{ steps.conditions.outputs.RUN_WEEKLY }}
          monthly: ${{ steps.conditions.outputs.RUN_MONTHLY }}
          force: ${{ github.event.inputs.force_summaries }}
          start-date: ${{ github.event.inputs.startDate }}
          end-date: ${{ github.event.inputs.endDate }}

      # Force regenerate steps also need correct order: repo -> contributor -> overall
      - name: Force regenerate recent repository summaries
        if: github.event_name == 'schedule' && steps.conditions.outputs.RUN_REPOSITORIES == 'true'
        uses: ./.github/actions/run-summary
        with:
          summary-type: "repository"
          daily: "true"
          force: "true"
          days: 1

      - name: Force regenerate recent contributor summaries
        if: github.event_name == 'schedule' && steps.conditions.outputs.RUN_CONTRIBUTORS == 'true'
        uses: ./.github/actions/run-summary
        with:
          summary-type: "contributors"
          daily: "true"
          force: "true"
          days: 1

      - name: Force regenerate recent overall summaries
        if: github.event_name == 'schedule'
        uses: ./.github/actions/run-summary
        with:
          summary-type: "overall"
          daily: "true"
          force: "true"
          days: 1

      # Dump SQLite database to diffable files
      - name: Dump SQLite database
        uses: ./.github/actions/restore-db
        with:
          operation: dump
          db_path: ${{ env.DATA_DIR }}/db.sqlite
          dump_dir: ${{ env.DATA_DIR }}/dump

      # Update pipeline-data branch with new summaries
      - name: Update pipeline-data branch with summaries
        uses: ./.github/actions/pipeline-data
        with:
          operation: update
          data_dir: ${{ env.DATA_DIR }}
          commit_message: "Summary generation run: $(date -u +'%Y-%m-%d %H:%M')"
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}

      # Cleanup worktree (always runs)
      - name: Cleanup
        if: always()
        uses: ./.github/actions/pipeline-data
        with:
          operation: cleanup
          data_dir: ${{ env.DATA_DIR }}
          branch_name: ${{ env.PIPELINE_DATA_BRANCH }}
