{
  "interval": {
    "intervalStart": "2025-12-20T00:00:00.000Z",
    "intervalEnd": "2025-12-21T00:00:00.000Z",
    "intervalType": "day"
  },
  "repository": "elizaos/elizaos.github.io",
  "overview": "From 2025-12-20 to 2025-12-21, elizaos/elizaos.github.io had 0 new PRs (0 merged), 1 new issues, and 1 active contributors.",
  "topIssues": [
    {
      "id": "I_kwDONNAI987figPq",
      "title": "RFC: Data Pipeline Architecture Improvements",
      "author": "madjin",
      "number": 187,
      "repository": "elizaos/elizaos.github.io",
      "body": "## Overview\n\nThis RFC documents our current data pipeline architecture and proposes improvements across several data engineering domains. Looking for team input on priorities and approach.\n\n## Current Architecture\n\nOur pipeline follows a **4-stage modular design**:\n\n```\nGitHub API → [Ingest] → SQLite (raw tables)\n                ↓\n           [Process] → SQLite (scores, tags, badges)\n                ↓\n            [Export] → JSON APIs (leaderboards, stats)\n                ↓\n          [Summarize] → AI summaries (repo, contributor, overall)\n                ↓\n           _data branch → GitHub Pages (static deployment)\n```\n\n### Strengths ✅\n- **Modular design** - Each stage independent, can run in isolation\n- **Sophisticated rate limiting** - Adaptive concurrency, token bucket, primary/secondary limit handling\n- **Data lineage via git** - `_data` branch with sqlite-diffable provides full audit trail\n- **Type safety** - TypeScript strict mode, Zod schemas, Drizzle ORM\n- **Configurable scoring** - Multi-dimensional metrics, per-type caps, tagging system\n- **Fork-friendly** - No hardcoded org values, env var overrides\n\n### Gaps & Risks ⚠️\n\n| Area | Gap | Risk Level |\n|------|-----|------------|\n| Idempotency | Partial updates possible if export fails mid-way | Medium |\n| Data Quality | No freshness alerts, anomaly detection, or reconciliation checks | Medium |\n| Observability | Limited visibility into pipeline health beyond logs | Low |\n| Error Recovery | No dead-letter queue, failures silently skipped in mapStep | Medium |\n| AI Summaries | Silent fallback if OpenRouter API down, no alerts | Low |\n| Scaling | Fixed concurrency, no pagination for large contributor lists | Low (for now) |\n\n---\n\n## Proposed Improvements\n\n### 1. Orchestration\n\n**Current:** GitHub Actions + CLI commands\n\n| Option | Fit | Effort | Notes |\n|--------|-----|--------|-------|\n| **Stay with GitHub Actions** | Good | - | Works, but limited DAG visibility and retry logic |\n| **Dagster** | Excellent | Medium | Asset-based model fits our pipeline, great UI, built-in lineage |\n| **Prefect** | Good | Medium | Python-native, good observability |\n| **Temporal** | Good | High | Best for durable long-running workflows (AI summaries) |\n\n**Recommendation:** Dagster aligns well with our \"assets\" mental model (raw tables → scores → summaries → JSON APIs). Provides lineage visualization, partial re-execution, and better failure handling.\n\n### 2. Data Quality & Integrity\n\n**Current:** Zod validation, uniqueness constraints, bot filtering\n\n**Proposed additions:**\n- [ ] Add `validate` pipeline stage with assertions:\n  - Row counts shouldn't decrease unexpectedly\n  - Scores within expected ranges (0-1000?)\n  - Freshness check (last ingest < 48 hours)\n  - Raw vs processed count reconciliation\n- [ ] Consider **Great Expectations** or **Soda** for declarative data contracts\n- [ ] Add anomaly detection (unusual spikes in contributors, scores)\n\n### 3. Data Governance\n\n**Current:** Git versioning via sqlite-diffable\n\n**Proposed additions:**\n- [ ] PII scrubbing - Hash or remove emails from commits table\n- [ ] Config versioning - Store scoring config snapshot with each pipeline run\n- [ ] Data catalog - Document table schemas, relationships, refresh cadence\n- [ ] Consider **DataHub** or **OpenMetadata** for lineage visualization (if we scale)\n\n### 4. Observability & Monitoring\n\n**Current:** Console logs only\n\n**Proposed additions:**\n- [ ] Pipeline metrics dashboard showing:\n  - Last successful run timestamp\n  - Duration per stage\n  - Record counts over time\n  - Error rate trends\n- [ ] Alerting on:\n  - Pipeline failures\n  - Data freshness violations (no ingest in 48h)\n  - Anomalous record count changes\n- [ ] GitHub Actions job summary with run statistics\n\n### 5. Architecture Evolution Paths\n\n**Path A: Incremental (Recommended for now)**\n```\nCurrent → Add data quality checks → Better logging/metrics → Dagster (later)\n```\n\n**Path B: Modern Data Stack**\n```\nSQLite → DuckDB → dbt for transforms → Dagster orchestration\n```\n\n**Path C: Event-Driven (Future, if needed for scale)**\n```\nGitHub Webhooks → Event queue → Real-time processing → Time-series DB\n```\n\n---\n\n## Proposed Priorities\n\n### Phase 1: Quick Wins (1-2 weeks)\n- [ ] Add row count logging after each pipeline stage\n- [ ] Create simple health check endpoint/page\n- [ ] Add dry-run flag to mutating commands\n- [ ] Implement basic freshness alerting\n\n### Phase 2: Data Quality (2-4 weeks)\n- [ ] Implement `validate` stage with core assertions\n- [ ] Add anomaly detection for key metrics\n- [ ] PII audit and scrubbing\n\n### Phase 3: Orchestration Upgrade (4-6 weeks)\n- [ ] Evaluate Dagster vs Temporal POC\n- [ ] Migrate one pipeline stage as proof of concept\n- [ ] Build observability dashboard\n\n---\n\n## Questions for Discussion\n\n1. **Priority:** Which gaps are most painful right now? What should we tackle first?\n2. **Orchestration:** Is the current GitHub Actions setup causing issues? Worth the migration effort?\n3. **Scale:** Are we expecting significant growth in repos/contributors that would change priorities?\n4. **Resources:** Who's interested in working on pipeline infrastructure?\n\n---\n\n## References\n\n- Current pipeline code: `src/lib/pipelines/`\n- Workflows: `.github/workflows/run-pipelines.yml`, `generate-summaries.yml`\n- Config: `config/example.json`\n- [Fundamentals of Data Engineering](https://www.oreilly.com/library/view/fundamentals-of-data/9781098108298/) - Reis & Housley",
      "createdAt": "2025-12-20T20:04:10Z",
      "closedAt": null,
      "state": "OPEN",
      "commentCount": 1
    }
  ],
  "topPRs": [],
  "codeChanges": {
    "additions": 0,
    "deletions": 0,
    "files": 0,
    "commitCount": 10
  },
  "completedItems": [],
  "topContributors": [
    {
      "username": "madjin",
      "avatarUrl": "https://avatars.githubusercontent.com/u/32600939?u=cdcf89f44c7a50906c7a80d889efa85023af2049&v=4",
      "totalScore": 2,
      "prScore": 0,
      "issueScore": 2,
      "reviewScore": 0,
      "commentScore": 0,
      "summary": "madjin: Initiated a significant architectural discussion by creating \"RFC: Data Pipeline Architecture Improvements\" (elizaos/elizaos.github.io#187), while also contributing to feature work, bug fixes, and other tasks across 21 files with 10 commits, modifying nearly 1000 lines of code."
    }
  ],
  "newPRs": 0,
  "mergedPRs": 0,
  "newIssues": 1,
  "closedIssues": 0,
  "activeContributors": 1
}