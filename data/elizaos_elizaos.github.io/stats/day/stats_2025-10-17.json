{
  "interval": {
    "intervalStart": "2025-10-17T00:00:00.000Z",
    "intervalEnd": "2025-10-18T00:00:00.000Z",
    "intervalType": "day"
  },
  "repository": "elizaos/elizaos.github.io",
  "overview": "From 2025-10-17 to 2025-10-18, elizaos/elizaos.github.io had 2 new PRs (3 merged), 4 new issues, and 2 active contributors.",
  "topIssues": [
    {
      "id": "I_kwDONNAI9864e7hZ",
      "title": "feat: Multi-repo support",
      "author": "madjin",
      "number": 108,
      "repository": "elizaos/elizaos.github.io",
      "body": "# Multi-Repository Support Implementation Tasks\n\nThis document breaks down the implementation tasks for adding multi-repository support to the Eliza Leaderboard, based on the phases outlined in `plan/multi-repo.md`.\n\n## Phase 1: Foundational Multi-Repo Support\n\n**Goal:** Enable the pipeline to ingest, process, and store data from multiple configured repositories, with basic per-repository output.\n\n-   [x] **Task 1.1: Modify `pipeline.config.ts` Structure**\n    -   [x] Update the `repositories` array in `config/pipeline.config.ts` to accept objects containing `owner`, `name`, and `repoId` (e.g., `{ owner: \"elizaos\", name: \"eliza\", repoId: \"elizaos/eliza\" }`).\n    -   [x] Ensure existing configuration loading logic correctly parses the new structure.\n    -   [x] Update type definitions for `PipelineConfig` to reflect this change.\n-   [ ] **Task 1.2: Update Core Pipeline Scripts for Iteration**\n    -   [ ] Modify the `ingest` pipeline in `cli/analyze-pipeline.ts` (and its underlying modules in `src/lib/pipelines/ingest/`) to iterate over each configured repository.\n        -   [ ] Pass the correct `repoId` (and owner/name if needed) to GitHub API calls and data processing functions.\n    -   [ ] Modify the `process` pipeline in `cli/analyze-pipeline.ts` (and `src/lib/pipelines/process/`) to operate on data from all configured repositories, ensuring `repoId` is used for correct association.\n    -   [ ] Modify the `export` pipeline in `cli/analyze-pipeline.ts` (and `src/lib/pipelines/export/`) to generate outputs for each repository, likely maintaining the `data/<owner_repo>/` structure.\n-   [ ] **Task 1.3: Ensure Data Segregation**\n    -   [ ] **Database:** Confirm that all database interactions (inserts, updates, queries) in Drizzle ORM correctly use the `repoId` (or equivalent `repository` field) to associate data with the correct repository (ref: `src/lib/data/schema.ts`).\n        -   [ ] Verify `repositories` table is populated correctly for each new repo.\n        -   [ ] Verify raw data tables (`rawPullRequests`, `rawIssues`, etc.) correctly link to `repositories.repoId`.\n    -   [ ] **File System:** Confirm that file-based outputs (JSON summaries, logs if any) are correctly placed in per-repository directories (e.g., `data/elizaos_eliza/`, `data/elizaos-plugins_myplugin/`).\n-   [ ] **Task 1.4: Verify Commit Deduplication**\n    -   [ ] Test the ingestion process with repositories that have shared commit history (if identifiable examples exist).\n    -   [ ] Confirm that commits with identical hashes are stored only once in `rawCommits` or are handled appropriately to avoid duplicate processing and scoring.\n        -   Investigate if `rawCommits.oid` (primary key) handles this naturally.\n-   [ ] **Task 1.5: Basic Per-Repository Reporting/Summarization**\n    -   [ ] Ensure the `summarize` pipeline (project summaries) can run for each configured repository and outputs to the correct `data/<owner_repo>/summaries/` directory.\n    -   [ ] Initial verification that existing website/UI components can (at a minimum) display data if pointed to a specific repository's output, or that per-repo pages can be generated. (Focus on data backend first).\n-   [ ] **Task 1.6: Update CLI Commands**\n    -   [ ] Review and update CLI command options in `cli/analyze-pipeline.ts` if necessary. For example, `--repository` flags might need to accept multiple values, or a new `--all-repos` flag might be introduced. Or, it might default to all repos in the config unless specified.\n    -   [ ] Update help messages and `README.md` for CLI changes.\n\n## Phase 2: Enhanced Scoring and Aggregation\n\n**Goal:** Develop strategies for viewing aggregated data (e.g., org-level) and explore more flexible scoring for a multi-repo context.\n\n-   [ ] **Task 2.1: Develop Aggregated View Strategies (Org-Level)**\n    -   [ ] Design how organization-level summaries or metrics could be calculated (e.g., total contributions to `elizaos` org).\n    -   [ ] Determine if new database tables or views are needed for storing/querying aggregated data.\n    -   [ ] Implement proof-of-concept for generating basic org-level statistics.\n-   [ ] **Task 2.2: Explore Flexible/Subjective Scoring Mechanisms**\n    -   [ ] Research and document potential approaches for allowing user-defined scoring weights (e.g., funders specifying weights for issue types, PR sizes, specific tags across selected repos).\n    -   [ ] Consider how `config/pipeline.config.ts` might be extended or if a new configuration mechanism/UI is needed for this.\n    -   [ ] Assess impact on `userTagScores` and `userDailyScores` if scores become more dynamic.\n-   [ ] **Task 2.3: Refine AI Summary Generation for Multi-Repo/Org Contexts**\n    -   [ ] Evaluate if the `projectContext` in `config/pipeline.config.ts` for AI summaries needs to be dynamic (e.g., different context per org, or a broader context for org-level summaries).\n    -   [ ] Test AI summary quality when summarizing activities across multiple repositories within an organization.\n    -   [ ] Adapt summarization prompts or logic in `src/lib/pipelines/summarize/` as needed.\n\n## Phase 3: Advanced Funder UX and LLM Integration\n\n**Goal:** Improve the user experience for stakeholders (funders) by providing better tools for data exploration and leveraging LLMs for insights.\n\n-   [ ] **Task 3.1: Design and Implement Enhanced Funder UX**\n    -   [ ] Brainstorm and mock up UI features that allow funders to:\n        -   [ ] Easily switch between per-repo, per-org, and global views.\n        -   [ ] Filter and sort contributors/contributions based on various criteria (tags, activity types, date ranges across multiple repos).\n        -   [ ] Apply their subjective scoring/weighting (if implemented in Phase 2).\n    -   [ ] Implement frontend changes in `src/app/` and related components.\n-   [ ] **Task 3.2: Integrate LLMs for Advanced Data Querying/Interpretation**\n    -   [ ] Explore feasibility of using LLMs to answer natural language questions about the contribution data (e.g., \"Show me top TypeScript contributors to elizaos-plugins this month\").\n    -   [ ] Design and prototype a system for this, considering data context provision to the LLM.\n\n## Cross-Cutting Concerns / To-Do Throughout\n\n-   [ ] **Testing:** Add unit and integration tests for multi-repo functionality.\n-   [ ] **Documentation:** Update `README.md`, `plan/multi-repo.md`, and any other relevant documentation.\n-   [ ] **Error Handling:** Ensure robust error handling for scenarios like invalid repo configurations, API errors for specific repos, etc.\n-   [ ] **Performance:** Monitor and optimize performance, especially during ingestion and processing of many repositories. Consider implications for `sqlite-diffable` and data sync.\n-   [ ] **GitHub Issue Creation:** Create corresponding GitHub issues for these tasks.\n-   [ ] **Branch Management:** Regularly merge changes from `main` to `multi-repo` and vice-versa as appropriate. ",
      "createdAt": "2025-05-27T20:25:14Z",
      "closedAt": "2025-10-17T23:41:25Z",
      "state": "CLOSED",
      "commentCount": 1
    },
    {
      "id": "I_kwDONNAI987DNaZ9",
      "title": "üéâ Your project has been featured in Awesome Claude Code!",
      "author": "hesreallyhim",
      "number": 149,
      "repository": "elizaos/elizaos.github.io",
      "body": "Hello! üëã\n\nI'm excited to let you know that **/context-prime** has been featured in the [Awesome Claude Code](https://github.com/hesreallyhim/awesome-claude-code) list!\n\n## About Awesome Claude Code\nAwesome Claude Code is a curated collection of the best slash-commands, CLAUDE.md files, CLI tools, and other resources for enhancing Claude Code workflows. Your project has been recognized for its valuable contribution to the Claude Code community.\n\n## Your Listing\nPrimes Claude with comprehensive project understanding by loading repository structure, setting development context, establishing project goals, and defining collaboration parameters.\n\nYou can find your entry here: [View in Awesome Claude Code](https://github.com/hesreallyhim/awesome-claude-code)\n\n## Show Your Recognition! üèÜ\nIf you'd like to display a badge in your README to show that your project is featured, you can use one of these:\n\n### Option 1: Standard Badge\n```markdown\n[![Mentioned in Awesome Claude Code](https://awesome.re/mentioned-badge.svg)](https://github.com/hesreallyhim/awesome-claude-code)\n```\n[![Mentioned in Awesome Claude Code](https://awesome.re/mentioned-badge.svg)](https://github.com/hesreallyhim/awesome-claude-code)\n\n### Option 2: Flat Badge\n```markdown\n[![Mentioned in Awesome Claude Code](https://awesome.re/mentioned-badge-flat.svg)](https://github.com/hesreallyhim/awesome-claude-code)\n```\n[![Mentioned in Awesome Claude Code](https://awesome.re/mentioned-badge-flat.svg)](https://github.com/hesreallyhim/awesome-claude-code)\n\n## No Action Required\nThis is just a friendly notification - no action is required on your part. Feel free to close this issue at any time.\n\nThank you for contributing to the Claude Code ecosystem! üôè\n\n---\n*This notification was sent because your project was added to the Awesome Claude Code list. This is a one-time notification.*",
      "createdAt": "2025-07-29T21:47:33Z",
      "closedAt": "2025-10-17T23:40:19Z",
      "state": "CLOSED",
      "commentCount": 1
    },
    {
      "id": "I_kwDONNAI986-HU5Y",
      "title": "Feat: Multirepo Frontend",
      "author": "META-DREAMER",
      "number": 139,
      "repository": "elizaos/elizaos.github.io",
      "body": "A. Main daily / weekly summary generation gets all the activity across all the repos. We update the prompt / format to organize the markdown with different sections for different repos.\n- This way the activity in other repos still appears in daily feed, without having to generate a bunch of repo-specific daily summaries that are empty\n- The main page section could have collapsible sections for details\n- Have 2-3 paragraphs of overall summary of all activity across all repos on daily summary\n\n\nB. Add new page for showing list of repos and their all time stats\n\nC. Click a repo to view a repo details page, which contains list of contributors, ai generated repo description, monthly summaries for that repo, active PR's, stats, visualization of activity history (similar to contributor profile page, but for a specific repo)",
      "createdAt": "2025-06-30T19:16:48Z",
      "closedAt": "2025-10-17T23:41:43Z",
      "state": "CLOSED",
      "commentCount": 0
    },
    {
      "id": "I_kwDONNAI987SQv6G",
      "title": "Enhancement: Add API cost estimation to ingestion pipeline",
      "author": "madjin",
      "number": 156,
      "repository": "elizaos/elizaos.github.io",
      "body": "# Enhancement: Add API cost estimation to ingestion pipeline\n\n## Context\nRunning `bun run pipeline ingest` with large date ranges can unexpectedly consume thousands of GitHub API calls, potentially hitting rate limits:\n- **Authenticated users**: 5,000 requests/hour\n- **GitHub Apps**: 15,000 requests/hour\n\nThis is especially problematic for:\n- Historical data ingestion (e.g., `--after 2024-01-01` on 20+ repos)\n- First-time project setup\n- Large active repositories with thousands of PRs/issues\n\n### Real-world example:\n- **23 repositories** √ó **52 weeks** √ó **~6 API calls per week** = **~7,176 API calls**\n- **Outcome**: Rate limit exhaustion, 1-2 hour wait, failed ingestion\n\nUsers need visibility into API cost before committing to large ingestions.\n\n## Proposal\nAdd `--estimate-only` flag and automatic pre-flight cost estimation that shows:\n- Estimated API call count\n- Risk level (LOW/MEDIUM/HIGH)\n- Estimated duration\n- Warning for HIGH risk operations\n\n## Implementation\n\n### Add cost estimation function to `cli/analyze-pipeline.ts`:\n\n```typescript\n// Simple API cost estimation helper\nfunction estimateApiCalls(\n  repositories: { owner: string; name: string }[],\n  intervalCount: number,\n): { total: number; risk: string; duration: number } {\n  const baseCallsPerRepo = intervalCount * 6; // ~6 calls per interval (PRs, issues, commits)\n  const total = repositories.length * baseCallsPerRepo;\n\n  const risk = total > 2000 ? \"HIGH\" : total > 500 ? \"MEDIUM\" : \"LOW\";\n  const duration = Math.ceil(total / 60); // ~60 calls per minute with rate limiting\n\n  return { total, risk, duration };\n}\n```\n\n### Add CLI flag to ingest command:\n\n```typescript\nprogram\n  .command(\"ingest\")\n  // ... existing options\n  .option(\n    \"--estimate-only\",\n    \"Show API cost estimation without executing ingestion\",\n    false,\n  )\n```\n\n### Add estimation logic before execution:\n\n```typescript\n// Calculate date range and intervals\nconst repositories = options.repository\n  ? pipelineConfig.repositories.filter(\n      (r) => `${r.owner}/${r.name}` === options.repository,\n    )\n  : pipelineConfig.repositories;\n\nconst daysDiff =\n  dateRange.endDate && dateRange.startDate\n    ? Math.ceil(\n        (new Date(dateRange.endDate).getTime() -\n          new Date(dateRange.startDate).getTime()) /\n          (1000 * 60 * 60 * 24),\n      )\n    : parseInt(options.days || \"7\");\nconst intervalCount = Math.ceil(daysDiff / 7); // Weekly intervals\n\nconst estimate = estimateApiCalls(repositories, intervalCount);\n\nrootLogger.info(`üìä Cost Estimation:`, {\n  repositories: repositories.length,\n  intervals: intervalCount,\n  estimatedApiCalls: estimate.total,\n  riskLevel: estimate.risk,\n  estimatedDuration: `${estimate.duration} minutes`,\n});\n\n// Handle estimate-only mode\nif (options.estimateOnly) {\n  console.log(`\\nüìã INGESTION ESTIMATE`);\n  console.log(`Repositories: ${repositories.length}`);\n  console.log(`Time intervals: ${intervalCount}`);\n  console.log(`Estimated API calls: ${estimate.total}`);\n  console.log(`Risk level: ${estimate.risk}`);\n  console.log(`Estimated duration: ${estimate.duration} minutes`);\n\n  if (estimate.risk === \"HIGH\") {\n    console.log(\n      `\\n‚ö†Ô∏è  HIGH RISK: Consider using smaller date ranges or --repository flag`,\n    );\n  }\n  return;\n}\n\n// Warn on high-risk operations\nif (estimate.risk === \"HIGH\") {\n  rootLogger.warn(\n    `‚ö†Ô∏è  High API usage detected (${estimate.total} calls). Monitor rate limits closely.`,\n  );\n}\n```\n\n## Benefits\n- ‚úÖ Prevents accidental rate limit exhaustion\n- ‚úÖ Better planning for large ingestions\n- ‚úÖ User can test with `--estimate-only` before committing\n- ‚úÖ Helpful for debugging and capacity planning\n- ‚úÖ No behavior change for existing commands (estimation is informational)\n\n## Trade-offs\n- Estimation is approximate (actual calls may vary by ¬±20%)\n- Adds ~65 lines of code total (11-line function + 1-line option + ~50 lines logic)\n- Risk thresholds are somewhat arbitrary (can be tuned based on team preferences)\n\n## Usage Examples\n\n### Check cost before running:\n```bash\n$ bun run pipeline ingest --after 2024-01-01 --estimate-only\n\nüìã INGESTION ESTIMATE\nRepositories: 23\nTime intervals: 52\nEstimated API calls: 7,176\nRisk level: HIGH\nEstimated duration: 120 minutes\n\n‚ö†Ô∏è  HIGH RISK: Consider using smaller date ranges or --repository flag\n```\n\n### Automatic estimation shown on every ingest:\n```bash\n$ bun run pipeline ingest --after 2024-01-01\n\nüìä Cost Estimation: {\n  repositories: 23,\n  intervals: 52,\n  estimatedApiCalls: 7176,\n  riskLevel: 'HIGH',\n  estimatedDuration: '120 minutes'\n}\n‚ö†Ô∏è  High API usage detected (7176 calls). Monitor rate limits closely.\n\nStarting ingestion...\n```\n\n### Test single repo first:\n```bash\n$ bun run pipeline ingest --after 2024-01-01 --repository elizaos/eliza --estimate-only\n\nüìã INGESTION ESTIMATE\nRepositories: 1\nTime intervals: 52\nEstimated API calls: 312\nRisk level: MEDIUM\nEstimated duration: 6 minutes\n```\n\n## Testing\nTested with various scenarios in https://github.com/M3-org/op-hiscores:\n- ‚úÖ Prevented 3 rate limit exhaustion scenarios during development\n- ‚úÖ Accurate within 15% of actual API calls in 10+ test runs\n- ‚úÖ Helped split large ingestions into manageable chunks\n\n## Files Modified\n- `cli/analyze-pipeline.ts` (~65 lines total: function + flag + logic)\n\n## References\n- Rate limiting best practices: https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api\n- Original implementation: M3-org/op-hiscores post-fork commits\n",
      "createdAt": "2025-10-17T21:22:45Z",
      "closedAt": "2025-10-18T07:26:03Z",
      "state": "CLOSED",
      "commentCount": 0
    },
    {
      "id": "I_kwDONNAI987SQvKZ",
      "title": "Enhancement: Add graceful shutdown to CLI pipeline",
      "author": "madjin",
      "number": 155,
      "repository": "elizaos/elizaos.github.io",
      "body": "# Enhancement: Add graceful shutdown to CLI pipeline\n\n## Context\nLong-running ingestion pipelines (historical data ingestion spanning months) can take hours, especially for large active repositories. Currently, pressing Ctrl+C immediately terminates the process, losing all in-progress work.\n\nThis is common when:\n- Ingesting historical data for the first time\n- Running large date range imports (e.g., `--after 2024-01-01`)\n- Processing multiple large repositories\n- Debugging or testing ingestion locally\n\n## Proposal\nAdd graceful shutdown handling that:\n1. **First Ctrl+C**: Completes current operation, saves progress, then exits cleanly\n2. **Second Ctrl+C**: Force exits immediately if user needs to stop now\n3. Shows clear messaging about shutdown state\n4. Allows resuming with same command (pipeline skips already-processed data)\n\n## Implementation\n\n### Add to `cli/analyze-pipeline.ts` (before program definition):\n\n```typescript\n// Graceful shutdown handler\nlet gracefulShutdown = false;\nprocess.on(\"SIGINT\", () => {\n  if (!gracefulShutdown) {\n    gracefulShutdown = true;\n    (global.process as { gracefulShutdown?: boolean }).gracefulShutdown = true;\n    console.log(\n      \"\\n‚ö†Ô∏è  Graceful shutdown initiated... Current operations will complete.\",\n    );\n    console.log(\"Press Ctrl+C again to force exit.\");\n  } else {\n    console.log(\"\\nüî¥ Force exit requested.\");\n    process.exit(1);\n  }\n});\n```\n\n### Update ingest command execution (in ingest action handler):\n\n```typescript\ntry {\n  await ingestPipeline(undefined, context);\n\n  if (gracefulShutdown) {\n    rootLogger.warn(\n      \"‚ö†Ô∏è  Ingestion interrupted but current operations completed successfully!\",\n    );\n    rootLogger.info(\n      \"üí° You can resume by running the same command again - the pipeline will skip already processed data.\",\n    );\n  } else {\n    rootLogger.info(\"‚úÖ Ingestion completed successfully!\");\n  }\n} catch (error: unknown) {\n  if (String(error).includes(\"GRACEFUL_SHUTDOWN\")) {\n    rootLogger.warn(\n      \"‚ö†Ô∏è  Ingestion gracefully interrupted. Progress has been saved.\",\n    );\n    rootLogger.info(\"üí° Resume by running the same command again.\");\n    return;\n  }\n  throw error;\n}\n```\n\n### Update `src/lib/pipelines/types.ts` mapStep to respect shutdown:\n\n```typescript\nconst results = await pMap(\n  inputs,\n  async (item, index) => {\n    // Check for graceful shutdown before processing each item\n    if (\n      global.process &&\n      (global.process as { gracefulShutdown?: boolean }).gracefulShutdown\n    ) {\n      context.logger?.warn(\n        `Graceful shutdown requested. Skipping remaining items after ${index}/${inputs.length}`,\n      );\n      throw new Error(\"GRACEFUL_SHUTDOWN\");\n    }\n    return await operation(item, context);\n  },\n  {\n    concurrency: Math.max(1, concurrency),\n    stopOnError: false, // Continue processing other items even if one fails\n  },\n);\n\nreturn results.filter((r) => r !== null); // Filter out any null results from interrupted operations\n```\n\n## Benefits\n- ‚úÖ Better UX for long-running operations (common in this project)\n- ‚úÖ No lost work on interruption - current operation completes\n- ‚úÖ Clear user feedback about shutdown state\n- ‚úÖ Resume capability - just re-run the same command\n- ‚úÖ Safety valve with double Ctrl+C for immediate exit\n\n## Trade-offs\n- Uses global state (`gracefulShutdown` flag on process object)\n- Adds ~30-40 lines of code\n- Slight complexity in pipeline execution flow\n\n## User Experience\n\n### Before (current behavior):\n```bash\n$ bun run pipeline ingest --after 2024-01-01\nFetching data for ethereum-optimism/optimism...\n^C [Process killed immediately, no progress saved]\n```\n\n### After (with graceful shutdown):\n```bash\n$ bun run pipeline ingest --after 2024-01-01\nFetching data for ethereum-optimism/optimism...\n^C\n‚ö†Ô∏è  Graceful shutdown initiated... Current operations will complete.\nPress Ctrl+C again to force exit.\n‚ö†Ô∏è  Ingestion interrupted but current operations completed successfully!\nüí° You can resume by running the same command again - the pipeline will skip already processed data.\n\n$ bun run pipeline ingest --after 2024-01-01\n[Resumes from where it left off]\n```\n\n## Testing\nTested extensively with multi-hour ingestions in: https://github.com/M3-org/op-hiscores\n- Graceful shutdown during PR ingestion ‚úÖ\n- Graceful shutdown during issue ingestion ‚úÖ\n- Resume capability verified ‚úÖ\n- Force exit (double Ctrl+C) verified ‚úÖ\n\n## Files Modified\n- `cli/analyze-pipeline.ts` (~20 lines added)\n- `src/lib/pipelines/types.ts` (~15 lines modified)\n\n## References\n- Original implementation: M3-org/op-hiscores commit range post-fork\n- Used successfully for 14 repository ingestions spanning 18K+ PRs\n",
      "createdAt": "2025-10-17T21:21:34Z",
      "closedAt": "2025-10-18T07:23:36Z",
      "state": "CLOSED",
      "commentCount": 0
    }
  ],
  "topPRs": [
    {
      "id": "PR_kwDONNAI986uZDUF",
      "title": "docs: add deployment guide for forks",
      "author": "madjin",
      "number": 158,
      "body": "## Summary\n\nFixes #154\n\nAdd comprehensive deployment guide for users forking this repository to deploy their own instance.\n\n## Problem\nThe README lacks documentation on:\n- How to configure `basePath` for subdirectory deployments\n- GitHub Pages setup steps\n- Required GitHub Actions secrets\n- Deployment architecture\n\nUsers forking the repo get 404 errors for all assets because Next.js tries to load from root path instead of subdirectory path.\n\n## Solution\nAdded new \"Deploying Your Own Instance\" section after \"CI/CD and Data Management\" section with:\n\n1. **basePath Configuration**: Clear instructions on when and how to add basePath to `next.config.js`\n2. **GitHub Pages Setup**: Step-by-step enable instructions\n3. **Required Secrets**: Complete list of secrets needed for Actions\n4. **Workflow Enablement**: How to enable and trigger workflows\n5. **Deployment Architecture**: Explains how `run-pipelines.yml` and `deploy.yml` work together\n\n## Changes\n- `README.md`: Added 54 lines of deployment documentation (inserted after line 344)\n\n## Key Clarifications\n- **Root deployment** (elizaos.github.io): No basePath needed\n- **Subdirectory deployment** (username.github.io/repo-name): basePath required\n- Explains organization vs personal account deployment differences\n\n## Testing\n‚úÖ Documentation validated against production fork deployment: https://m3-org.github.io/op-hiscores/\n‚úÖ basePath configuration tested and working\n\n## Impact\n- ‚úÖ Clear fork deployment instructions\n- ‚úÖ Prevents common 404 errors\n- ‚úÖ Documents all required secrets in one place\n- ‚úÖ Better onboarding for contributors",
      "repository": "elizaos/elizaos.github.io",
      "createdAt": "2025-10-17T21:40:48Z",
      "mergedAt": "2025-10-17T23:34:40Z",
      "additions": 59,
      "deletions": 0
    },
    {
      "id": "PR_kwDONNAI986uY78G",
      "title": "fix: dynamically copy stats for all tracked repositories",
      "author": "madjin",
      "number": 157,
      "body": "## Summary\n\nFixes #153 \n\nReplace hardcoded `elizaos_eliza` path with dynamic loop to copy stats files for all 23 tracked repositories.\n\n## Problem\nCurrently only 1 of 23 repositories gets its stats copied. The workflow hardcodes `data/elizaos_eliza/stats/...` at line 68, leaving 22 other repositories with stale `stats.json` files.\n\n## Solution\n- Loop through `data/*/` directories dynamically\n- Skip non-repository directories (`dump`, `summaries`)\n- Add per-repository status logging\n- Graceful handling if stats file is missing\n\n## Changes\n- `.github/workflows/deploy.yml`: Replace 2 lines with 27-line dynamic loop\n\n## Testing\n‚úÖ Tested with 14 repositories in production fork: https://m3-org.github.io/op-hiscores/\n‚úÖ All repository stats successfully copied\n‚úÖ Non-repo directories properly skipped\n\n## Verification\nVerified against current `_data` branch structure:\n- 23 repository directories found\n- All follow `owner_repo` naming convention\n- All have `stats/day/` subdirectories\n\n## Impact\n- ‚úÖ Works with all 23 repositories\n- ‚úÖ Future-proof (no hardcoded repo names)\n- ‚úÖ Backward compatible\n- ‚úÖ Better debugging with clear logging",
      "repository": "elizaos/elizaos.github.io",
      "createdAt": "2025-10-17T21:27:42Z",
      "mergedAt": "2025-10-17T23:32:47Z",
      "additions": 7,
      "deletions": 2
    },
    {
      "id": "PR_kwDONNAI986ljq92",
      "title": "Add elizaos/docs repo tracking and claude bot exclusion",
      "author": "wtfsayo",
      "number": 151,
      "body": "## Summary\n- Add elizaos/docs repository to the tracked repositories list for contributor analytics\n- Add \"claude\" to bot users exclusion list to filter out Claude Code contributions from analytics\n\n## Changes\n- Added `elizaos/docs` repository with `main` as default branch to `repositories` array\n- Added `\"claude\"` to `botUsers` array to exclude Claude Code contributions from scoring\n\n## Test plan\n- [ ] Verify pipeline configuration loads without errors\n- [ ] Run pipeline ingest to test elizaos/docs repository tracking\n- [ ] Confirm claude user contributions are properly filtered out\n\nü§ñ Generated with [Claude Code](https://claude.ai/code)",
      "repository": "elizaos/elizaos.github.io",
      "createdAt": "2025-08-27T08:27:02Z",
      "mergedAt": "2025-10-17T04:24:13Z",
      "additions": 6,
      "deletions": 0
    }
  ],
  "codeChanges": {
    "additions": 72,
    "deletions": 2,
    "files": 3,
    "commitCount": 6
  },
  "completedItems": [
    {
      "title": "Add elizaos/docs repo tracking and claude bot exclusion",
      "prNumber": 151,
      "type": "other",
      "body": "## Summary\n- Add elizaos/docs repository to the tracked repositories list for contributor analytics\n- Add \"claude\" to bot users exclusion list to filter out Claude Code contributions from analytics\n\n## Changes\n- Added `elizaos/docs` reposit",
      "files": [
        "config/pipeline.config.ts"
      ]
    },
    {
      "title": "docs: add deployment guide for forks",
      "prNumber": 158,
      "type": "docs",
      "body": "## Summary\n\nFixes #154\n\nAdd comprehensive deployment guide for users forking this repository to deploy their own instance.\n\n## Problem\nThe README lacks documentation on:\n- How to configure `basePath` for subdirectory deployments\n- GitHub Pa",
      "files": [
        "README.md"
      ]
    },
    {
      "title": "fix: dynamically copy stats for all tracked repositories",
      "prNumber": 157,
      "type": "bugfix",
      "body": "## Summary\n\nFixes #153 \n\nReplace hardcoded `elizaos_eliza` path with dynamic loop to copy stats files for all 23 tracked repositories.\n\n## Problem\nCurrently only 1 of 23 repositories gets its stats copied. The workflow hardcodes `data/eliza",
      "files": [
        ".github/workflows/deploy.yml"
      ]
    }
  ],
  "topContributors": [
    {
      "username": "standujar",
      "avatarUrl": "https://avatars.githubusercontent.com/u/16385918?u=718bdcd1585be8447bdfffb8c11ce249baa7532d&v=4",
      "totalScore": 83.06048829440076,
      "prScore": 83.06048829440076,
      "issueScore": 0,
      "reviewScore": 0,
      "commentScore": 0,
      "summary": "standujar: Focused on documentation and scaffolding improvements, merging two PRs including a significant update to plugin documentation and scaffolding issues in elizaos/eliza#6071 (+1098/-834 lines), alongside a fix for a misleading comment in elizaos/eliza#6072. This work primarily involved bug fixes, documentation, and tests."
    },
    {
      "username": "madjin",
      "avatarUrl": "https://avatars.githubusercontent.com/u/32600939?u=cdcf89f44c7a50906c7a80d889efa85023af2049&v=4",
      "totalScore": 68.04746482760808,
      "prScore": 51.409464827608076,
      "issueScore": 16.2,
      "reviewScore": 0,
      "commentScore": 0.43799999999999994,
      "summary": "madjin: Focused on documentation and configuration improvements, merging two PRs including a deployment guide for forks (elizaos/elizaos.github.io#158) and dynamically copying stats for tracked repositories (elizaos/elizaos.github.io#157), while also creating and closing several issues related to enhancements and bug fixes. Their primary focus was on bugfix work, with contributions split between documentation and configuration files."
    },
    {
      "username": "ryanmstokes",
      "avatarUrl": "https://avatars.githubusercontent.com/u/4103619?u=fc6560a14f83b275fdc9442d884182000fb818e1&v=4",
      "totalScore": 4.2,
      "prScore": 0,
      "issueScore": 4.2,
      "reviewScore": 0,
      "commentScore": 0,
      "summary": "ryanmstokes: Focused on documentation accuracy, creating and closing an issue in elizaos/eliza (#6070) to address incorrect plugin documentation."
    },
    {
      "username": "borisudovicic",
      "avatarUrl": "https://avatars.githubusercontent.com/u/31806472?u=8935f4d43fd7e4eb9bf5ff92d54d4d2f8ac8a786&v=4",
      "totalScore": 2,
      "prScore": 0,
      "issueScore": 2,
      "reviewScore": 0,
      "commentScore": 0,
      "summary": "borisudovicic: Focused on strategic planning and foundational improvements, creating four issues including \"Consistency & Stability\" (elizaos/eliza#5934), \"Add Eigen TEE Deployment Option\" (elizaos/eliza#5986), and \"Cloud API Plugin for Framework LLMs\" (elizaos/eliza#6049), all of which were subsequently closed, alongside an open issue to \"Standardize Logging Across Core, CLI, and Server\" (elizaos/eliza#6073)."
    },
    {
      "username": "wtfsayo",
      "avatarUrl": "https://avatars.githubusercontent.com/u/82053242?u=98209a1f10456f42d4d2fa71db4d5bf4a672cbc3&v=4",
      "totalScore": 0.2,
      "prScore": 0,
      "issueScore": 0,
      "reviewScore": 0,
      "commentScore": 0.2,
      "summary": "wtfsayo: Today, wtfsayo engaged in substantial code modifications across 172 files, adding over 10,000 lines and removing nearly 5,000 lines through 10 commits, primarily focusing on other work, bug fixes, and refactoring, and also contributed to an issue discussion."
    }
  ],
  "newPRs": 2,
  "mergedPRs": 3,
  "newIssues": 4,
  "closedIssues": 5,
  "activeContributors": 2
}